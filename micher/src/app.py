####### CARREGAR DADOS #####
import os
import json
import pandas as pd
import subprocess
import streamlit as st

# BASE_DIR aponta para a raiz do projeto (uma pasta acima de src)
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

# CONFIGURA√á√ïES
MODELO = "gpt-oss"
MAX_TOKENS = 300  # limite de tokens, apenas para refer√™ncia

# CARREGAR ARQUIVOS JSON E CSV
perfil = json.load(open(os.path.join(BASE_DIR, 'data', 'perfil_investidor.json'), encoding='utf-8'))
transacoes = pd.read_csv(os.path.join(BASE_DIR, 'data', 'transacoes.csv'))
historico = pd.read_csv(os.path.join(BASE_DIR, 'data', 'historico_atendimento.csv'))
produtos = json.load(open(os.path.join(BASE_DIR, 'data', 'produtos_financeiros.json'), encoding='utf-8'))

### MONTAR CONTEXTO ###
contexto = f"""
CLIENTE: {perfil['nome']}, {perfil['idade']} anos, perfil {perfil['perfil_investidor']}
OBJETIVO: {perfil['objetivo_principal']}
PATRIM√îNIO: R$ {perfil['patrimonio_total']} | RESERVA R$ {perfil['reserva_emergencia_atual']}

TRANSA√á√ïES RECENTES:
{transacoes.to_string(index=False)}

ATENDIMENTOS ANTERIORES:
{historico.to_string(index=False)}

PRODUTOS DISPON√çVEIS:
{json.dumps(produtos, indent=2, ensure_ascii=False)}
"""

### SYSTEM PROMPT ###
SYSTEM_PROMPT = """Voc√™ √© o Micher, um educador financeiro amig√°vel e did√°tico.

OBJETIVO:
Ensinar conceitos de finan√ßas pessoais de forma simples, usando os dados do cliente como exemplos pr√°ticos.

REGRAS:
1- Nunca recomente investimentos espec√≠ficos - apenas explique como funciona
2- Use os dados fornecidos para exemplos personalizados
3- Linguagem simples, como se explicasse para um amigo
4- Se n√£o souber algo, admita: "N√£o tenho essa informa√ß√£o, mas posso explicar..."
5- Sempre pergunte se o cliente entendeu
[CONTEXTO: USO DA BASE DE CONHECIMENTO]
"""

### FUN√á√ÉO PARA CHAMAR OLLAMA VIA CLI ###
def perguntar(msg):
    """
    Chama o modelo Ollama local usando a CLI, adaptado para a vers√£o sem '--prompt'.
    """
    prompt = f"{SYSTEM_PROMPT}\n\nCONTEXTO DO CLIENTE:\n{contexto}\n\nPergunta: {msg}"
    try:
        result = subprocess.run(
            ["ollama", "run", MODELO, prompt],
            capture_output=True,
            text=True,
            timeout=30
        )
        if result.returncode != 0:
            return f"Erro ao executar Ollama CLI: {result.stderr.strip()}"
        return result.stdout.strip()
    except subprocess.TimeoutExpired:
        return "O Ollama demorou muito para responder."
    except Exception as e:
        return f"Ocorreu um erro ao chamar Ollama: {e}"


### INTERFACE STREAMLIT ###
st.set_page_config(page_title="Micher - Educador Financeiro", page_icon="üë®‚Äçüéì")

st.title("üë®‚Äçüéì Sou Micher, seu educador Financeiro")

# Inicializa o hist√≥rico de chat no Streamlit
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Input do usu√°rio
if pergunta_usuario := st.chat_input("Sua d√∫vida sobre finan√ßas..."):
    st.session_state.chat_history.append({"role": "user", "message": pergunta_usuario})
    with st.spinner("Gerando resposta..."):
        resposta = perguntar(pergunta_usuario)
        st.session_state.chat_history.append({"role": "assistant", "message": resposta})

# Exibir hist√≥rico
for chat in st.session_state.chat_history:
    if chat["role"] == "user":
        st.chat_message("user").write(chat["message"])
    else:
        st.chat_message("assistant").write(chat["message"])
